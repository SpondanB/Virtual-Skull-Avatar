# Head Poseâ€“Driven 3D Skull

## Overview
This project demonstrates a **real-time, camera-driven 3D animation system** where a virtual skull mirrors a user's **head orientation, eye blinks, and mouth movements** using a standard webcam.

It combines **computer vision**, **3D geometry**, and **real-time rendering**, showcasing practical skills in:
- Humanâ€“computer interaction
- Face tracking and pose estimation
- Lightweight 3D graphics (using pygame) without game engines
- Physics-inspired Particle Systems

This project was built entirely from scratch using **Python**, without relying on high-level 3D engines such as Unity or Blender.

This project is an updated version of the previous [Face Tracker Project](https://github.com/SpondanB/FaceTracker) that I did. The final result of that project is added in the "Old version" directory.

---

## Key Features

| Feature                | Description                                    |
| ---------------------- | ---------------------------------------------- |
| ğŸ§­ Head Pose Tracking  | Pitch, Yaw, Roll control the skull orientation |
| ğŸ‘ Blink Detection     | Eye Aspect Ratio controls eyelid animation     |
| ğŸ‘„ Mouth Tracking      | Jaw opens and closes with your mouth           |
| ğŸ’€ Custom 3D skull mesh      | Rendered using just the mathematical coordinates |
| âœ¨ Particle Aura        | Procedural floating particles under the jaw    |
| ğŸ’¡ Lighting System     | Face normal lighting with depth sorting        |
| ğŸ® Real-Time Rendering | 60 FPS Pygame 3D renderer                      |

---

## Technical Highlights
- **MediaPipe Face Mesh** for facial landmark detection
- **Perspective-n-Point (PnP)** for 3D head pose estimation
- **Manual 3D projection pipeline** (no OpenGL / no engines)
- **Z-bufferâ€“like face sorting** for correct rendering order
- **Temporal smoothing** to prevent jitter and flipping
- **Procedural animation** for jaw and eyelids

---

## ğŸ§© System Architecture

```
Webcam â†’ MediaPipe Face Mesh â†’ SolvePnP â†’ Rotation Matrix
                     â†“
         Blink + Mouth Detection
                     â†“
     3D Skull Transformation + Jaw Rig
                     â†“
     Lighting + Projection + Z-Sorting
                     â†“
           Pygame Renderer
```

---

## ğŸ§  Key Concepts Demonstrated

### 1. Head Pose Estimation

* 3D face model + 2D landmarks
* `cv2.solvePnP()` estimates camera-space rotation
* Rodrigues â†’ Rotation Matrix â†’ Euler Angles

### 2. 3D Rendering Pipeline

* Custom vertex buffer
* Face normal lighting
* Perspective projection
* Depth sorting (Painterâ€™s Algorithm)

### 3. Facial Animation

* Eye Aspect Ratio â†’ Blink animation
* Mouth distance â†’ Jaw rigging
* Smooth interpolation for realism

### 4. Particle System

* Procedural particle emission
* Physics-based motion
* Lifetime fading
* Alpha blending

---

## Installation

### Requirements
- A standard device with Python (3.10) installed
- mentioned list of python packages
- Webcam

### Install dependencies
```bash
pip install requirements.txt
```

---

## How to Run
```bash
python Main.py
```

Controls:
- Move your head â†’ skull rotates
- Blink â†’ eye sockets dim
- Open mouth â†’ jaw moves

Press **close** on the window to exit.

---

## Project Structure
```
â”œâ”€â”€ Old version
|   â””â”€â”€ OldVer.py # Result of the previous attempt
â”œâ”€â”€ Tests         # Test applications
|   â”œâ”€â”€ test-3d-obj.py
|   â”œâ”€â”€ test-combined-with-blinking.py
|   â”œâ”€â”€ test-combined.py
|   â”œâ”€â”€ test-rpy-calc.py
|   â””â”€â”€ test-thread-combined.py
â”œâ”€â”€ Main.py        # Core application
â””â”€â”€ README.md      # Project documentation
```

---

## Design Decisions
- **No external 3D engines**: to demonstrate raw understanding of 3D math
- **Low-level rendering**: polygons drawn manually via Pygame
- **Robust pose smoothing**: prevents sudden 180Â° flips common in PnP
- **Physically inspired motion**: jaw motion uses proportional translation

---

## Potential Extensions
- Texture-mapped faces
- Emotion-based facial deformation
- Audio-driven lip-sync
- Export to OpenGL / WebGL
- Multi-face tracking

---

## â­ Why This Project Matters

This project showcases:

* Advanced applied linear algebra
* Real-time computer vision pipelines
* Interactive 3D graphics from scratch

---

## Author
**Spondan Bandyopadhyay**  
Interests: Computer Vision, Graphics, AI Systems, Human-Computer Interaction

---
